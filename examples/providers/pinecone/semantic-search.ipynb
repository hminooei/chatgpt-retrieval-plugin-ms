{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Pinecone Retrieval App\n",
    "\n",
    "In this walkthrough we will see how to use the retrieval API with a Pinecone datastore for *semantic search / question-answering*.\n",
    "\n",
    "Before running this notebook you should have already initialized the retrieval API and have it running locally or elsewhere. The full instructions for doing this are found in the [project README]().\n",
    "\n",
    "We will summarize the instructions (specific to the Pinecone datastore) before moving on to the walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Python 3.10 if not already installed.\n",
    "\n",
    "2. Clone the `retrieval-app` repository:\n",
    "\n",
    "```\n",
    "git clone git@github.com:openai/retrieval-app.git\n",
    "```\n",
    "\n",
    "3. Navigate to the app directory:\n",
    "\n",
    "```\n",
    "cd /path/to/retrieval-app\n",
    "```\n",
    "\n",
    "4. Install `poetry`:\n",
    "\n",
    "```\n",
    "pip install poetry\n",
    "```\n",
    "\n",
    "5. Create a new virtual environment:\n",
    "\n",
    "```\n",
    "poetry env use python3.10\n",
    "```\n",
    "\n",
    "6. Install the `retrieval-app` dependencies:\n",
    "\n",
    "```\n",
    "poetry install\n",
    "```\n",
    "\n",
    "7. Set app environment variables:\n",
    "\n",
    "* `BEARER_TOKEN`: Secret token used by the app to authorize incoming requests. We will later include this in the request `headers`. The token can be generated however you prefer, such as using [jwt.io](https://jwt.io/).\n",
    "\n",
    "* `OPENAI_API_KEY`: The OpenAI API key used for generating embeddings with the `text-embedding-ada-002` model. [Get an API key here](https://platform.openai.com/account/api-keys)!\n",
    "\n",
    "8. Set Pinecone-specific environment variables:\n",
    "\n",
    "* `DATASTORE`: set to `pinecone`.\n",
    "\n",
    "* `PINECONE_API_KEY`: Set to your Pinecone API key. This requires a free Pinecone account and can be [found in the Pinecone console](https://app.pinecone.io/).\n",
    "\n",
    "* `PINECONE_ENVIRONMENT`: Set to your Pinecone environment, looks like `us-east1-gcp`, `us-west1-aws`, and can be found next to your API key in the [Pinecone console](https://app.pinecone.io/).\n",
    "\n",
    "* `PINECONE_INDEX`: Set this to your chosen index name. The name you choose is your choice, we just recommend setting it to something descriptive like `\"openai-retrieval-app\"`. *Note that index names are restricted to alphanumeric characters, `\"-\"`, and can contain a maximum of 45 characters.*\n",
    "\n",
    "8. Run the app with:\n",
    "\n",
    "```\n",
    "poetry run start\n",
    "```\n",
    "\n",
    "If running the app locally you should see something like:\n",
    "\n",
    "```\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8000\n",
    "INFO:     Application startup complete.\n",
    "```\n",
    "\n",
    "In that case, the app is automatically connected to our index (specified by `PINECONE_INDEX`), if no index with that name existed beforehand, the app creates one for us.\n",
    "\n",
    "Now we're ready to move on to populating our index with some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few Python libraries we must `pip install` for this notebook to run, those are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU datasets pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the **S**tanford **Qu**estion **A**nswering **D**ataset (SQuAD), which we download from Hugging Face Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.27k/5.27k [00:00<00:00, 1.86MB/s]\n",
      "Downloading metadata: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.36k/2.36k [00:00<00:00, 1.42MB/s]\n",
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.67k/7.67k [00:00<00:00, 4.35MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text to /Users/hminooei/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|                                                                                                                                                                      | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                                                                                      | 0.00/8.12M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  32%|██████████████████████████████████████████████████▋                                                                                                          | 2.62M/8.12M [00:00<00:00, 26.2MB/s]\u001b[A\n",
      "Downloading data:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 7.06M/8.12M [00:00<00:00, 36.9MB/s]\u001b[A\n",
      "Downloading data: 13.7MB [00:00, 50.5MB/s]                                                                                                                                                                               \u001b[A\n",
      "Downloading data: 21.8MB [00:00, 62.4MB/s]\u001b[A\n",
      "Downloading data: 30.3MB [00:00, 60.1MB/s]\u001b[A\n",
      "Downloading data files:  50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 1/2 [00:00<00:00,  1.38it/s]\n",
      "Downloading data: 4.85MB [00:00, 49.2MB/s]                                                                                                                                                                               \u001b[A\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.05it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 615.41it/s]\n",
      "                                                                                                                                                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /Users/hminooei/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"squad\", split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Pandas dataframe for easier preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title   \n",
       "0  5733be284776f41900661182  University_of_Notre_Dame  \\\n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context   \n",
       "0  Architecturally, the school has a Catholic cha...  \\\n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question   \n",
       "0  To whom did the Virgin Mary allegedly appear i...  \\\n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to_pandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a lot of duplicate `context` paragraphs, this is because each `context` can have many relevant questions. We don't want these duplicates so we remove like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5733bf84d058e614000b61be</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>When did the Scholastic Magazine of Notre dame...</td>\n",
       "      <td>{'text': ['September 1876'], 'answer_start': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5733bed24776f41900661188</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>Where is the headquarters of the Congregation ...</td>\n",
       "      <td>{'text': ['Rome'], 'answer_start': [119]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5733a6424776f41900660f51</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "      <td>How many BS level degrees are offered in the C...</td>\n",
       "      <td>{'text': ['eight'], 'answer_start': [487]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5733a70c4776f41900660f64</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>All of Notre Dame's undergraduate students are...</td>\n",
       "      <td>What entity provides help with the management ...</td>\n",
       "      <td>{'text': ['Learning Resource Center'], 'answer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id                     title   \n",
       "0   5733be284776f41900661182  University_of_Notre_Dame  \\\n",
       "5   5733bf84d058e614000b61be  University_of_Notre_Dame   \n",
       "10  5733bed24776f41900661188  University_of_Notre_Dame   \n",
       "15  5733a6424776f41900660f51  University_of_Notre_Dame   \n",
       "20  5733a70c4776f41900660f64  University_of_Notre_Dame   \n",
       "\n",
       "                                              context   \n",
       "0   Architecturally, the school has a Catholic cha...  \\\n",
       "5   As at most other universities, Notre Dame's st...   \n",
       "10  The university is the major seat of the Congre...   \n",
       "15  The College of Engineering was established in ...   \n",
       "20  All of Notre Dame's undergraduate students are...   \n",
       "\n",
       "                                             question   \n",
       "0   To whom did the Virgin Mary allegedly appear i...  \\\n",
       "5   When did the Scholastic Magazine of Notre dame...   \n",
       "10  Where is the headquarters of the Congregation ...   \n",
       "15  How many BS level degrees are offered in the C...   \n",
       "20  What entity provides help with the management ...   \n",
       "\n",
       "                                              answers  \n",
       "0   {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "5   {'text': ['September 1876'], 'answer_start': [...  \n",
       "10          {'text': ['Rome'], 'answer_start': [119]}  \n",
       "15         {'text': ['eight'], 'answer_start': [487]}  \n",
       "20  {'text': ['Learning Resource Center'], 'answer...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset=[\"context\"])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format required by the apps `upsert` function is a list of documents like:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"id\": \"abc\",\n",
    "        \"text\": \"some important document text\",\n",
    "        \"metadata\": {\n",
    "            \"field1\": \"optional metadata goes here\",\n",
    "            \"field2\": 54\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"123\",\n",
    "        \"text\": \"some other important text\",\n",
    "        \"metadata\": {\n",
    "            \"field1\": \"another metadata\",\n",
    "            \"field2\": 71,\n",
    "            \"field3\": \"not all metadatas need the same structure\"\n",
    "        }\n",
    "    }\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Every document *must* have a `\"text\"` field. The `\"id\"` and `\"metadata\"` fields are optional.\n",
    "\n",
    "To create this format for our SQuAD data we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '5733be284776f41900661182',\n",
       "  'text': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "  'metadata': {'title': 'University_of_Notre_Dame'}},\n",
       " {'id': '5733bf84d058e614000b61be',\n",
       "  'text': \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\",\n",
       "  'metadata': {'title': 'University_of_Notre_Dame'}},\n",
       " {'id': '5733bed24776f41900661188',\n",
       "  'text': 'The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.',\n",
       "  'metadata': {'title': 'University_of_Notre_Dame'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    {\n",
    "        'id': r['id'],\n",
    "        'text': r['context'],\n",
    "        'metadata': {\n",
    "            'title': r['title']\n",
    "        }\n",
    "    } for r in data.to_dict(orient='records')\n",
    "]\n",
    "documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing the Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to begin indexing (or *upserting*) our `documents`. To make these requests to the retrieval app API, we will need to provide authorization in the form of the `BEARER_TOKEN` we set earlier. We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BEARER_TOKEN = os.environ.get(\"BEARER_TOKEN\") or \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkhhZGkgTWlub29laSIsImlhdCI6MTUxNjIzOTAyMn0.Ggr5MBFnLBKqVnpasGRiX536Tl3wwIqL1gqaui4QDhY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `BEARER_TOKEN` to create our authorization `headers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform the upsert in batches of `batch_size`. Make sure that the `endpoint_url` variable is set to the correct location for your running *retrieval-app* API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [41:03<00:00, 13.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "batch_size = 100\n",
    "endpoint_url = \"http://localhost:8000\"\n",
    "s = requests.Session()\n",
    "\n",
    "# we setup a retry strategy to retry on 5xx errors\n",
    "retries = Retry(\n",
    "    total=5,  # number of retries before raising error\n",
    "    backoff_factor=0.1,\n",
    "    status_forcelist=[500, 502, 503, 504]\n",
    ")\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    i_end = min(len(documents), i+batch_size)\n",
    "    # make post request that allows up to 5 retries\n",
    "    res = s.post(\n",
    "        f\"{endpoint_url}/upsert\",\n",
    "        headers=headers,\n",
    "        json={\n",
    "            \"documents\": documents[i:i_end]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdownify\n",
      "  Downloading markdownify-0.11.6-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdownify) (4.12.1)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdownify) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.4)\n",
      "Installing collected packages: markdownify\n",
      "Successfully installed markdownify-0.11.6\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install markdownify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Importing BeautifulSoup class from the bs4 module\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # Opening the html file\n",
    "# HTMLFile = open(\"/Users/hminooei/Downloads/site/amazon-s3-connector/0.3.7/index.html\")\n",
    "\n",
    "# # Reading the file\n",
    "# index = HTMLFile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option one to convert html to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import markdownify\n",
    "\n",
    "# # convert html to markdown\n",
    "# h = markdownify.markdownify(index, heading_style=\"ATX\")\n",
    "\n",
    "# # print markdown\n",
    "# print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option two to convert html to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import html2text\n",
    "\n",
    "# text = html2text.html2text(index)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting all the html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "site_path = '/Users/hminooei/Downloads/site-4-2023'\n",
    "html_files = []\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".html\"):\n",
    "            # print(os.path.join(root, name))\n",
    "            html_files.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all the html file to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _chain_from_iterable_of_lists at 0x7fa6a86770b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from pinecone.utils import html_to_md\n",
    "\n",
    "md_folder = 'site-files'\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    executor.map(html_to_md, html_files, [md_folder]*len(html_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the preamble, and ending of the md files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "site_path = 'site-files'\n",
    "md_files = []\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".md\"):\n",
    "            md_files.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _chain_from_iterable_of_lists at 0x7fa6a8c29a50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from pinecone.utils import truncate_mulesoft_site_md_pages\n",
    "\n",
    "md_folder = 'site-files'\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    executor.map(truncate_mulesoft_site_md_pages, md_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Due to the chatgpt bug, changing the file extensions to txt\n",
    "import os\n",
    "\n",
    "site_path = 'site-files'\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".md\"):\n",
    "            pre, ext = os.path.splitext(os.path.join(root, name))\n",
    "            os.rename(os.path.join(root, name), pre[:-4] + \"txt\") # pre[:-4] removes the html from the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "site_path = 'site-files'\n",
    "txt_files = []\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".txt\"):\n",
    "            txt_files.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt_files = [p for p in txt_files if \".ipynb_checkpoints\" not in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending documents to the doc-store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "endpoint_url = \"http://localhost:8000\"\n",
    "s = requests.Session()\n",
    "\n",
    "# we setup a retry strategy to retry on 5xx errors\n",
    "retries = Retry(\n",
    "    total=5,  # number of retries before raising error\n",
    "    backoff_factor=0.1,\n",
    "    status_forcelist=[500, 502, 503, 504]\n",
    ")\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Given the inconsistency of the mimetype, although the mimetype of the files are now \n",
    "# # text/plain but apparently chatgpt's code sees them as unauthorized type.\n",
    "# for p in tqdm(txt_files[:2]):\n",
    "#     # make post request that allows up to 5 retries\n",
    "#     # mimetype, _ = mimetypes.guess_type(p)\n",
    "#     # print(mimetype)   \n",
    "#     with open(p, 'rb') as f:\n",
    "#         res = s.post(\n",
    "#             f\"{endpoint_url}/upsert-file\",\n",
    "#             headers=headers,\n",
    "#             files={'file':f}\n",
    "#         ) \n",
    "#         print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10114/10114 [00:03<00:00, 3025.73it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for p in tqdm(txt_files):\n",
    "    with open(p, 'r') as f:\n",
    "        text = f.read()\n",
    "        documents.append(\n",
    "            {\n",
    "                'id': p,\n",
    "                'text': text,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102/102 [2:23:52<00:00, 84.63s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    i_end = min(len(documents), i+batch_size)\n",
    "    # make post request that allows up to 5 retries\n",
    "    res = s.post(\n",
    "        f\"{endpoint_url}/upsert\",\n",
    "        headers=headers,\n",
    "        json={\n",
    "            \"documents\": documents[i:i_end]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries = [\n",
    "           {'query': \"What's dataweave?\"},\n",
    "           {'query': \"How to install s3 connector?\"}, \n",
    "           {'query': \"how to create api groups?\"},\n",
    "           {'query': \"mapObject example in dataweave\"},\n",
    "           {'query': \"DataWeave example that sorts an array by a field\"},\n",
    "           # {'query': \"who is the current president of USA?\"},\n",
    "           # {'query': \"Hi, how are you?\"},\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "endpoint_url = \"http://localhost:8000\"\n",
    "s = requests.Session()\n",
    "\n",
    "res = requests.post(\n",
    "    \"http://0.0.0.0:8000/query\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        'queries': queries\n",
    "    }\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = res.json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for n in range(len(queries)):\n",
    "#     print('Query: ', results[n]['query'])\n",
    "#     for m in range(3):\n",
    "#         print(\"id: \", results[n]['results'][m]['metadata']['document_id'])\n",
    "#         print(\"score: \", results[n]['results'][m]['score'])\n",
    "#         print(\"answer: \", results[n]['results'][m]['text'])\n",
    "#         print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "What's dataweave?\n",
      "\n",
      "\n",
      "0.89:  [site-files/_Users_hminooei_Downloads_site-4-2023_mule-runtime_4.4_dataweave.txt]\n",
      ": # DataWeave Overview  DataWeave is a programming language designed by MuleSoft for accessing and transforming data that travels through a Mule application. Mule runtime engine incorporates DataWeave in several core components like Transform and Set Payload, which enable you to execute DataWeave scripts and expressions in your Mule app.  DataWeave scripts act on data in the Mule event. Most commonly, you use it to access and transform data in the message payload. For example, after a component in your Mule app retrieves data from one system, you can use DataWeave to modify and output selected fields in that data to a new data format, then use another component in your app to pass on that data to another system.    * To get started with DataWeave 2.4.0 for Mule runtime engine (Mule) version 4.4 and later, visit [the quickstart](../..\n",
      "\n",
      "0.89:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_1.2_index.txt]\n",
      ": This version of the product has entered [Extended Support](https://www.mulesoft.com/legal/versioning-back-support- policy#extended-support).  ×  # DataWeave Language  The [DataWeave Language](dataweave-language-introduction) is a simple, powerful tool used to query and transform data inside of Mule. It can be implemented to:    * graphically map fields by dragging one attribute to another, just like you were able to with the now deprecated [DataMapper](../../studio/6.x/datamapper-user-guide-and-reference), or    * leverage its powerful object-oriented language that's specially designed to make writing transformations quick, without compromising maintainability.  DataWeave supports a variety of transformations: simple **one-to-one** , **one-to-many** or **many-to-one** mappings from an assortment of data structures, and can complete more elaborate mappings including normalization, grouping, joins, partitioning, pivoting and filtering.\n",
      "\n",
      "0.89:  [site-files/_Users_hminooei_Downloads_site-4-2023_mule-runtime_4.2_migration-mel.txt]\n",
      ": DataWeave is a Mule-specific language that can be used lightly as an expression language to simply reference values and evaluate conditions, or as a scripting language to construct complex data transformations that include functions and recursion.  Unlike MEL, it supports different data types out of the box, like JSON, XML, or CSV, which means data no longer needs to be transformed before expressions can be evaluated. It also supports advanced use cases like mapping functions or filtering data.  It's important to notice that the main data selector in DataWeave is the `.` operator. Since it shares most keywords with MEL, the syntax for most scenarios is identical. For example, `#[message.payload.name]` is the same in both languages.  The main difference between MEL and DataWeave is that DataWeave expressions have no side effects. You can use DataWeave to extract or generate data but not to modify it.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "How to install s3 connector?\n",
      "\n",
      "\n",
      "0.87:  [site-files/_Users_hminooei_Downloads_site-4-2023_amazon-s3-connector_5.6_amazon-s3-connector-studio.txt]\n",
      ": 5. Select the connector and click **Add to project**.    6. Follow the prompts to install the connector.  ### Add the Connector in Studio    1. In Studio, create a Mule project.    2. In the Mule Palette view, click **(X) Search in Exchange**.    3. In **Add Modules to Project** , type \"s3\" in the search field.    4. Click this connector's name in **Available modules**.    5. Click **Add**.    6. Click **Finish**.  ## Configure an Input Source  Configure an input source for Amazon S3 Connector, such as a connector operation, HTTP connector, or scheduler.  You can put the following operations for the connector in the **Source** area of the Studio canvas:    * **On Deleted Object** Initiates access to your app when an Amazon S3 object is deleted.\n",
      "\n",
      "0.86:  [site-files/_Users_hminooei_Downloads_site-4-2023_amazon-s3-connector_0.3.9_index.txt]\n",
      ": 5.0 or later      **AWS SDK for Java**  |  1.11.515      ## Install the Connector    1. In Anypoint Studio, click the Exchange icon in the Studio taskbar.    2. Sign in to Exchange with your Anypoint Platform credentials.    3. From Anypoint Exchange, click **Provided by MuleSoft**.    4. Search for the Mule 3 connector and click **Install**.  When Studio has an update, a message displays in the lower right corner, which you can click to install the update.  ## Configure a Global Element  To use Amazon S3 Connector in your Mule app, configure a global Amazon S3 element that can be used by all the Amazon S3 connectors in the app (read more about [Global Elements](../../mule-runtime/3.9/global-elements)).    1.\n",
      "\n",
      "0.86:  [site-files/_Users_hminooei_Downloads_site-4-2023_amazon-s3-connector_5.7_amazon-s3-connector-xml-maven.txt]\n",
      ": [Example](amazon-s3-connector-examples).\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "how to create api groups?\n",
      "\n",
      "\n",
      "0.9:  [site-files/_Users_hminooei_Downloads_site-4-2023_api-manager_2.x_api-groups-creating-groups.txt]\n",
      ": You create API Groups using the following steps:    1. Create an API Group  The first step to creating an API Group that can be used by consumers is to create an API Group.    2. Add API instances to the new API Group  After you create the API Group, you then add API instances to this group for the first time.  ## Task Prerequisites  Before you begin, you must have:    * At least one API instance in your organization or business group  Otherwise, you will not be able to find the required organization or business group in the list.    * API Group Administrator permissions to create API Groups  ## Create API Groups  You create an API Group at the organization level.  To create API Groups:    1. From the left menu in **API Manager** , click **API Groups > Create API Group**.    2.\n",
      "\n",
      "0.88:  [site-files/_Users_hminooei_Downloads_site-4-2023_api-manager_2.x_api-groups-creating-groups.txt]\n",
      ": [API Manager](./)   3. [Manage API Groups](api-groups-landing-page)   4. Create API Groups  # Create API Groups and Add API Instances  To package a set of APIs, you first create an API Group and then add the relevant API instances to the group. If you want your API Group to be discovered by consumers, you must publish it to Exchange.  Using the following information, you create an API Group, including creating an API Group, creating the very first version of that group, and creating the very first group instance. Additionally, you add API instances to the API Group instance.  You can add API instances to the API Group instance based on the environment (production, sandbox, or others) in which you create the API Group instance. For example, if you created an API Group instance in a production environment, you can add API instances to the API Group instance only from production.\n",
      "\n",
      "0.87:  [site-files/_Users_hminooei_Downloads_site-4-2023_api-manager_2.x_api-groups-creating-groups.txt]\n",
      ": In the **API Group name** field, specify a name for the API Group that you want to create: for example, `Social Chatter`.    3. In the **API Group version** field, specify the version for the API Group: for example, `v1`.    4. Optionally, in the **API Group instance label** field, specify a label for the API Group, such as `Internal` if you want to use it for internal purposes.    5. Click **Continue**.  The **Creating a new group** page is displayed. You are now ready to add API instances to the API Group.  ## Add API Instances to API Groups  Your API Group is not functional until you add the API instances to the group that you want to bundle. When you add API instances to an API Group, you can add:    * Only those API instances that belong in the same business group or organizations\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "mapObject example in dataweave\n",
      "\n",
      "\n",
      "0.88:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_2.4_dataweave-cookbook-map-an-object.txt]\n",
      ": [DataWeave](./)   3. [DataWeave Examples](dataweave-cookbook)   4. Map an Object  # Map Objects  The following DataWeave examples use the `mapObject` function to iterate through the keys and values of objects. Before you begin, note that 2.x versions of DataWeave are used by Mule 4 apps. For DataWeave in Mule 3 apps, refer to [DataWeave version 1.2 examples](../1.2/dataweave-examples). For other DataWeave versions, you can use the version selector in the DataWeave table of contents.  ## First Example  This example uses both the `map` and `mapObject` functions to iterate through the input and set all of the keys to upper case.  The example uses these DataWeave functions:\n",
      "\n",
      "0.87:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_2.4_dataweave-cookbook-map-an-object-key.txt]\n",
      ": # Map Objects Key  This DataWeave example uses the `mapObject` function to iterate through an array of objects and appends a new object that matches the value of the specified criteria.  Before you begin, note that 2.x versions of DataWeave are used by Mule 4 apps. For DataWeave in Mule 3 apps, refer to [DataWeave version 1.2 examples](../1.2/dataweave-examples). For other DataWeave versions, you can use the version selector in the DataWeave table of contents.  The input consists of a JSON object with sheets. The value of every sheet (for example, `(sheet)1`, `(sheet)2`) is an array of objects. The DataWeave script adds another object `append` as the last item to the matched sheet array if\n",
      "\n",
      "0.87:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_1.2_dataweave-examples.txt]\n",
      ": [**map object** operation](dataweave-operators#map-object) and a [**map** operation](dataweave-operators#map). Note that they differ in that map object processes both key and value of its input, rather than just the keys. It also uses the [**filter** operation](dataweave-operators#filter) to only show the attendees that have the class subject listed as a hobby. As each student may have multiple hobbies, the [**Multi value** selector](dataweave- selectors#multi-value-selector) is used to refer to them all.  ### Example Transformation  DataWeave                %dw 1.0     %output application/dw     ---     classrooms: payload.school.teachers groupBy $.subject mapObject ((teacherGroup, subject) -> {         class: {           name: subject,           teachers: { (teacherGroup map {             teacher:{                 name: $.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DataWeave example that sorts an array by a field\n",
      "\n",
      "\n",
      "0.87:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_2.4_dataweave-cookbook-pick-top-elements.txt]\n",
      ": [DataWeave](./)   3. [DataWeave Examples](dataweave-cookbook)   4. Pick Top Elements  # Pick Top Elements  This DataWeave example sorts an array of candidates by the score they got in a test, then picks only the ones with the best score, as many as there are open positions to fill. Before you begin, note that 2.x versions of DataWeave are used by Mule 4 apps. For DataWeave in Mule 3 apps, refer to [DataWeave version 1.2 examples](../1.2/dataweave-examples). For other DataWeave versions, you can use the version selector in the DataWeave table of contents.  This example uses the following:    * `map` to go through each of the candidates in the input.    * `orderBy` to order the list of candidates according to their score.\n",
      "\n",
      "0.85:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_2.3_dataweave-cookbook-pick-top-elements.txt]\n",
      ": [DataWeave](./)   3. [DataWeave Examples](dataweave-cookbook)   4. Pick Top Elements  This version of the product has entered [Extended Support](https://www.mulesoft.com/legal/versioning-back-support- policy#extended-support). You can switch to the [latest version](https://docs.mulesoft.com/dataweave/2.4/dataweave-cookbook-pick-top- elements), or use the version selector in the left navigation.  ×  # Pick Top Elements  This DataWeave example sorts an array of candidates by the score they got in a test, then picks only the ones with the best score, as many as there are open positions to fill. Before you begin, note that DataWeave version 2 (`%dw 2.0`) is for Mule 4 apps.\n",
      "\n",
      "0.84:  [site-files/_Users_hminooei_Downloads_site-4-2023_dataweave_2.4_dataweave-cookbook-zip-arrays-together.txt]\n",
      ": [DataWeave](./)   3. [DataWeave Examples](dataweave-cookbook)   4. Zip Arrays Together  # Zip Arrays Together  This DataWeave example restructures bills of materials for Ikea-style furniture. The input contains the measurements and amounts of screws in two separate arrays that run in parallel, the transformation reorders them so that the \"screws\" array is made up of tuples, each with a measurement and its corresponding amount. The same is applied to wooden boards: the input contains two arrays with the x and the y measurements of each; the transformation rearranges them into a series of tuples, one for each board. Before you begin, note that 2.x versions of DataWeave are used by Mule 4 apps. For DataWeave in Mule 3 apps, refer to [DataWeave version 1.2 examples](../1.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_result in res.json()['results']:\n",
    "    query = query_result['query']\n",
    "    answers = []\n",
    "    scores = []\n",
    "    doc_ids = []\n",
    "    for result in query_result['results']:\n",
    "        answers.append(result['text'])\n",
    "        scores.append(round(result['score'], 2))\n",
    "        doc_ids.append(result['metadata']['document_id'])\n",
    "    print(\"-\"*70+\"\\n\"+query+\"\\n\\n\"+\"\\n\".join([f\"\\n{s}:  [{d}]\\n: {a}\" for a, s, d in zip(answers, scores, doc_ids)])+\"\\n\"+\"-\"*70+\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1979a773a5778de9a5fa593a629dff0ab3c80c2563810d3e6a8dfb123dc01c7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
