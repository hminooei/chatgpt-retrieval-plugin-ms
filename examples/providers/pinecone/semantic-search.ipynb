{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Pinecone Retrieval App\n",
    "\n",
    "In this walkthrough we will see how to use the retrieval API with a Pinecone datastore for *semantic search / question-answering*.\n",
    "\n",
    "Before running this notebook you should have already initialized the retrieval API and have it running locally or elsewhere. The full instructions for doing this are found in the [project README]().\n",
    "\n",
    "We will summarize the instructions (specific to the Pinecone datastore) before moving on to the walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Python 3.10 if not already installed.\n",
    "\n",
    "2. Clone the `retrieval-app` repository:\n",
    "\n",
    "```\n",
    "git clone git@github.com:openai/retrieval-app.git\n",
    "```\n",
    "\n",
    "3. Navigate to the app directory:\n",
    "\n",
    "```\n",
    "cd /path/to/retrieval-app\n",
    "```\n",
    "\n",
    "4. Install `poetry`:\n",
    "\n",
    "```\n",
    "pip install poetry\n",
    "```\n",
    "\n",
    "5. Create a new virtual environment:\n",
    "\n",
    "```\n",
    "poetry env use python3.10\n",
    "```\n",
    "\n",
    "6. Install the `retrieval-app` dependencies:\n",
    "\n",
    "```\n",
    "poetry install\n",
    "```\n",
    "\n",
    "7. Set app environment variables:\n",
    "\n",
    "* `BEARER_TOKEN`: Secret token used by the app to authorize incoming requests. We will later include this in the request `headers`. The token can be generated however you prefer, such as using [jwt.io](https://jwt.io/).\n",
    "\n",
    "* `OPENAI_API_KEY`: The OpenAI API key used for generating embeddings with the `text-embedding-ada-002` model. [Get an API key here](https://platform.openai.com/account/api-keys)!\n",
    "\n",
    "8. Set Pinecone-specific environment variables:\n",
    "\n",
    "* `DATASTORE`: set to `pinecone`.\n",
    "\n",
    "* `PINECONE_API_KEY`: Set to your Pinecone API key. This requires a free Pinecone account and can be [found in the Pinecone console](https://app.pinecone.io/).\n",
    "\n",
    "* `PINECONE_ENVIRONMENT`: Set to your Pinecone environment, looks like `us-east1-gcp`, `us-west1-aws`, and can be found next to your API key in the [Pinecone console](https://app.pinecone.io/).\n",
    "\n",
    "* `PINECONE_INDEX`: Set this to your chosen index name. The name you choose is your choice, we just recommend setting it to something descriptive like `\"openai-retrieval-app\"`. *Note that index names are restricted to alphanumeric characters, `\"-\"`, and can contain a maximum of 45 characters.*\n",
    "\n",
    "8. Run the app with:\n",
    "\n",
    "```\n",
    "poetry run start\n",
    "```\n",
    "\n",
    "If running the app locally you should see something like:\n",
    "\n",
    "```\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8000\n",
    "INFO:     Application startup complete.\n",
    "```\n",
    "\n",
    "In that case, the app is automatically connected to our index (specified by `PINECONE_INDEX`), if no index with that name existed beforehand, the app creates one for us.\n",
    "\n",
    "Now we're ready to move on to populating our index with some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few Python libraries we must `pip install` for this notebook to run, those are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU datasets pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the **S**tanford **Qu**estion **A**nswering **D**ataset (SQuAD), which we download from Hugging Face Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.27k/5.27k [00:00<00:00, 1.86MB/s]\n",
      "Downloading metadata: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.36k/2.36k [00:00<00:00, 1.42MB/s]\n",
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.67k/7.67k [00:00<00:00, 4.35MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text to /Users/hminooei/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|                                                                                                                                                                      | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                                                                                      | 0.00/8.12M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  32%|██████████████████████████████████████████████████▋                                                                                                          | 2.62M/8.12M [00:00<00:00, 26.2MB/s]\u001b[A\n",
      "Downloading data:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 7.06M/8.12M [00:00<00:00, 36.9MB/s]\u001b[A\n",
      "Downloading data: 13.7MB [00:00, 50.5MB/s]                                                                                                                                                                               \u001b[A\n",
      "Downloading data: 21.8MB [00:00, 62.4MB/s]\u001b[A\n",
      "Downloading data: 30.3MB [00:00, 60.1MB/s]\u001b[A\n",
      "Downloading data files:  50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 1/2 [00:00<00:00,  1.38it/s]\n",
      "Downloading data: 4.85MB [00:00, 49.2MB/s]                                                                                                                                                                               \u001b[A\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.05it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 615.41it/s]\n",
      "                                                                                                                                                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /Users/hminooei/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"squad\", split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Pandas dataframe for easier preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title   \n",
       "0  5733be284776f41900661182  University_of_Notre_Dame  \\\n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context   \n",
       "0  Architecturally, the school has a Catholic cha...  \\\n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question   \n",
       "0  To whom did the Virgin Mary allegedly appear i...  \\\n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to_pandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a lot of duplicate `context` paragraphs, this is because each `context` can have many relevant questions. We don't want these duplicates so we remove like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5733bf84d058e614000b61be</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>When did the Scholastic Magazine of Notre dame...</td>\n",
       "      <td>{'text': ['September 1876'], 'answer_start': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5733bed24776f41900661188</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>Where is the headquarters of the Congregation ...</td>\n",
       "      <td>{'text': ['Rome'], 'answer_start': [119]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5733a6424776f41900660f51</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "      <td>How many BS level degrees are offered in the C...</td>\n",
       "      <td>{'text': ['eight'], 'answer_start': [487]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5733a70c4776f41900660f64</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>All of Notre Dame's undergraduate students are...</td>\n",
       "      <td>What entity provides help with the management ...</td>\n",
       "      <td>{'text': ['Learning Resource Center'], 'answer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id                     title   \n",
       "0   5733be284776f41900661182  University_of_Notre_Dame  \\\n",
       "5   5733bf84d058e614000b61be  University_of_Notre_Dame   \n",
       "10  5733bed24776f41900661188  University_of_Notre_Dame   \n",
       "15  5733a6424776f41900660f51  University_of_Notre_Dame   \n",
       "20  5733a70c4776f41900660f64  University_of_Notre_Dame   \n",
       "\n",
       "                                              context   \n",
       "0   Architecturally, the school has a Catholic cha...  \\\n",
       "5   As at most other universities, Notre Dame's st...   \n",
       "10  The university is the major seat of the Congre...   \n",
       "15  The College of Engineering was established in ...   \n",
       "20  All of Notre Dame's undergraduate students are...   \n",
       "\n",
       "                                             question   \n",
       "0   To whom did the Virgin Mary allegedly appear i...  \\\n",
       "5   When did the Scholastic Magazine of Notre dame...   \n",
       "10  Where is the headquarters of the Congregation ...   \n",
       "15  How many BS level degrees are offered in the C...   \n",
       "20  What entity provides help with the management ...   \n",
       "\n",
       "                                              answers  \n",
       "0   {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "5   {'text': ['September 1876'], 'answer_start': [...  \n",
       "10          {'text': ['Rome'], 'answer_start': [119]}  \n",
       "15         {'text': ['eight'], 'answer_start': [487]}  \n",
       "20  {'text': ['Learning Resource Center'], 'answer...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset=[\"context\"])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format required by the apps `upsert` function is a list of documents like:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"id\": \"abc\",\n",
    "        \"text\": \"some important document text\",\n",
    "        \"metadata\": {\n",
    "            \"field1\": \"optional metadata goes here\",\n",
    "            \"field2\": 54\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"123\",\n",
    "        \"text\": \"some other important text\",\n",
    "        \"metadata\": {\n",
    "            \"field1\": \"another metadata\",\n",
    "            \"field2\": 71,\n",
    "            \"field3\": \"not all metadatas need the same structure\"\n",
    "        }\n",
    "    }\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Every document *must* have a `\"text\"` field. The `\"id\"` and `\"metadata\"` fields are optional.\n",
    "\n",
    "To create this format for our SQuAD data we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '5733be284776f41900661182',\n",
       "  'text': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "  'metadata': {'title': 'University_of_Notre_Dame'}},\n",
       " {'id': '5733bf84d058e614000b61be',\n",
       "  'text': \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\",\n",
       "  'metadata': {'title': 'University_of_Notre_Dame'}},\n",
       " {'id': '5733bed24776f41900661188',\n",
       "  'text': 'The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.',\n",
       "  'metadata': {'title': 'University_of_Notre_Dame'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    {\n",
    "        'id': r['id'],\n",
    "        'text': r['context'],\n",
    "        'metadata': {\n",
    "            'title': r['title']\n",
    "        }\n",
    "    } for r in data.to_dict(orient='records')\n",
    "]\n",
    "documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing the Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to begin indexing (or *upserting*) our `documents`. To make these requests to the retrieval app API, we will need to provide authorization in the form of the `BEARER_TOKEN` we set earlier. We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BEARER_TOKEN = os.environ.get(\"BEARER_TOKEN\") or \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkhhZGkgTWlub29laSIsImlhdCI6MTUxNjIzOTAyMn0.Ggr5MBFnLBKqVnpasGRiX536Tl3wwIqL1gqaui4QDhY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `BEARER_TOKEN` to create our authorization `headers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform the upsert in batches of `batch_size`. Make sure that the `endpoint_url` variable is set to the correct location for your running *retrieval-app* API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [41:03<00:00, 13.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "batch_size = 100\n",
    "endpoint_url = \"http://localhost:8000\"\n",
    "s = requests.Session()\n",
    "\n",
    "# we setup a retry strategy to retry on 5xx errors\n",
    "retries = Retry(\n",
    "    total=5,  # number of retries before raising error\n",
    "    backoff_factor=0.1,\n",
    "    status_forcelist=[500, 502, 503, 504]\n",
    ")\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    i_end = min(len(documents), i+batch_size)\n",
    "    # make post request that allows up to 5 retries\n",
    "    res = s.post(\n",
    "        f\"{endpoint_url}/upsert\",\n",
    "        headers=headers,\n",
    "        json={\n",
    "            \"documents\": documents[i:i_end]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdownify\n",
      "  Downloading markdownify-0.11.6-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdownify) (4.12.1)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdownify) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.4)\n",
      "Installing collected packages: markdownify\n",
      "Successfully installed markdownify-0.11.6\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install markdownify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Importing BeautifulSoup class from the bs4 module\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # Opening the html file\n",
    "# HTMLFile = open(\"/Users/hminooei/Downloads/site/amazon-s3-connector/0.3.7/index.html\")\n",
    "\n",
    "# # Reading the file\n",
    "# index = HTMLFile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option one to convert html to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import markdownify\n",
    "\n",
    "# # convert html to markdown\n",
    "# h = markdownify.markdownify(index, heading_style=\"ATX\")\n",
    "\n",
    "# # print markdown\n",
    "# print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option two to convert html to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import html2text\n",
    "\n",
    "# text = html2text.html2text(index)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting all the html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "site_path = '/Users/hminooei/Downloads/site'\n",
    "html_files = []\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".html\"):\n",
    "            # print(os.path.join(root, name))\n",
    "            html_files.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all the html file to markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from pinecone.utils import html_to_md\n",
    "\n",
    "md_folder = 'site-files'\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    executor.map(html_to_md, html_files, [md_folder]*len(html_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the preamble, and ending of the md files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "site_path = 'site-files'\n",
    "md_files = []\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".md\"):\n",
    "            md_files.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from pinecone.utils import truncate_mulesoft_site_md_pages\n",
    "\n",
    "md_folder = 'site-files'\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    executor.map(truncate_mulesoft_site_md_pages, md_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Due to the chatgpt bug, changing the file extensions to txt\n",
    "import os\n",
    "\n",
    "site_path = 'site-files'\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".md\"):\n",
    "            pre, ext = os.path.splitext(os.path.join(root, name))\n",
    "            os.rename(os.path.join(root, name), pre[:-4] + \"txt\") # pre[:-4] removes the html from the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "site_path = 'site-files'\n",
    "txt_files = []\n",
    "for root, dirs, files in os.walk(site_path, topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".txt\"):\n",
    "            txt_files.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt_files = [p for p in txt_files if \".ipynb_checkpoints\" not in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending documents to the doc-store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "endpoint_url = \"http://localhost:8000\"\n",
    "s = requests.Session()\n",
    "\n",
    "# we setup a retry strategy to retry on 5xx errors\n",
    "retries = Retry(\n",
    "    total=5,  # number of retries before raising error\n",
    "    backoff_factor=0.1,\n",
    "    status_forcelist=[500, 502, 503, 504]\n",
    ")\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Given the inconsistency of the mimetype, although the mimetype of the files are now \n",
    "# # text/plain but apparently chatgpt's code sees them as unauthorized type.\n",
    "# for p in tqdm(txt_files[:2]):\n",
    "#     # make post request that allows up to 5 retries\n",
    "#     # mimetype, _ = mimetypes.guess_type(p)\n",
    "#     # print(mimetype)   \n",
    "#     with open(p, 'rb') as f:\n",
    "#         res = s.post(\n",
    "#             f\"{endpoint_url}/upsert-file\",\n",
    "#             headers=headers,\n",
    "#             files={'file':f}\n",
    "#         ) \n",
    "#         print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13517/13517 [00:01<00:00, 7289.37it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for p in tqdm(txt_files):\n",
    "    with open(p, 'r') as f:\n",
    "        text = f.read()\n",
    "        documents.append(\n",
    "            {\n",
    "                'id': p,\n",
    "                'text': text,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 271/271 [1:23:22<00:00, 18.46s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    i_end = min(len(documents), i+batch_size)\n",
    "    # make post request that allows up to 5 retries\n",
    "    res = s.post(\n",
    "        f\"{endpoint_url}/upsert\",\n",
    "        headers=headers,\n",
    "        json={\n",
    "            \"documents\": documents[i:i_end]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries = [{'query': \"What's dataweave?\"},\n",
    "           {'query': \"How to install s3 connector?\"}, \n",
    "           {'query': \"how to create api groups?\"},\n",
    "           {'query': \"mapObject example in dataweave\"},\n",
    "           {'query': \"DataWeave example that sorts an array by a field\"}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "endpoint_url = \"http://localhost:8000\"\n",
    "s = requests.Session()\n",
    "\n",
    "res = requests.post(\n",
    "    \"http://0.0.0.0:8000/query\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        'queries': queries\n",
    "    }\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = res.json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What's dataweave?\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_1.1_dataweave-reference-documentation.txt\n",
      "score:  0.894097149\n",
      "answer:  The DataWeave Language is a powerful template engine that allows you to transform data to and from any kind of format (XML, CSV, JSON, Pojos, Maps, etc).  Let us start off with some examples to demonstrate the prowess of Dataweave as a data transformation tool.  ## Basic Example  This example shows a simple mapping from JSON to XML  Input                {       \"title\": \"Java 8 in Action: Lambdas, Streams, and functional-style programming\",       \"author\": \"Mario Fusco\",       \"year\": 2014     }  Transform                %dw 1.0     %output application/xml     ---     {       order: {         type: \"Book\",         title: payload.title,         details: \"By $(payload.author) ($(payload.year))\"       }     }  Output                <?xml version='1.0' encoding='UTF-8'?>     <order>\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.3_index.txt\n",
      "score:  0.887545645\n",
      "answer:  Menu    1. [ ](../../general/index.html)   2. [DataWeave](index.html)   3. [DataWeave Language](index.html)  # DataWeave Language  DataWeave is the programming language designed by MuleSoft for data transformation. It is also the expression language Mule runtime engine uses to configure components and connectors.  DataWeave enables you to build a simple solution for a common use case for integration developers: read and parse data from one format, transform the data, and write it out as a different format. For example, a DataWeave script can receive a CSV file as input and transform it into an array of complex JSON objects, or receive an XML input and write the data out to a flat file format. DataWeave enables developers to focus on the transformation logic instead of thinking about the specifics of reading, parsing, and writing specific data\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.4_index.txt\n",
      "score:  0.887501419\n",
      "answer:  Menu    1. [ ](../../general/index.html)   2. [DataWeave](index.html)   3. [DataWeave Language](index.html)  # DataWeave Language  DataWeave is the programming language designed by MuleSoft for data transformation. It is also the expression language Mule runtime engine uses to configure components and connectors.  DataWeave enables you to build a simple solution for a common use case for integration developers: read and parse data from one format, transform the data, and write it out as a different format. For example, a DataWeave script can receive a CSV file as input and transform it into an array of complex JSON objects, or receive an XML input and write the data out to a flat file format. DataWeave enables developers to focus on the transformation logic instead of thinking about the specifics of reading, parsing, and writing specific data\n",
      "----\n",
      "\n",
      "Query:  How to install s3 connector?\n",
      "id:  site-files/_Users_hminooei_Downloads_site_amazon-s3-connector_0.3.8_index.txt\n",
      "score:  0.871451795\n",
      "answer:  3. Search for the connector and click Install.    4. Follow the prompts to install the connector.  When Studio has an update, a message displays in the lower right corner, which you can click to install the update.  When prompted:    1. Select the **Amazon S3 connector version 4.3.0** check box and click **Next**.    2. Follow the instructions provided by the user interface.    3. Restart Studio when prompted. After restarting, if you have several versions of the connector installed, Mule asks you for the version of the connector to use.  ## Configuring the Connector Global Element  To use the Amazon S3 connector in your Mule application, configure a global Amazon S3 element that can be used by all the Amazon S3 connectors in the application (read more about [Global Elements](../../mule-runtime/3.8/global- elements.html).)  ### Studio Visual Editor\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_amazon-s3-connector_0.3.7_index.txt\n",
      "score:  0.870690882\n",
      "answer:  3. Search for the connector and click Install.    4. Follow the prompts to install the connector.  When Studio has an update, a message displays in the lower right corner, which you can click to install the update.  When prompted:    1. Select the **Amazon S3 connector version 4.3.0** check box and click **Next**.    2. Follow the instructions provided by the user interface.    3. Restart Studio when prompted. After restarting, if you have several versions of the connector installed, Mule asks you for the version of the connector to use.  ## Configuring the Connector Global Element  To use the Amazon S3 connector in your Mule application, configure a global Amazon S3 element that can be used by all the Amazon S3 connectors in the application (read more about [Global Elements](../../mule-runtime/3.7/global- elements.html).)  ### Studio Visual Editor\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_amazon-s3-connector_5.6_amazon-s3-connector-studio.txt\n",
      "score:  0.86795634\n",
      "answer:  Click the Exchange icon **(X)** in the upper-left of the Studio task bar.    3. In Exchange, click **Login** and supply your Anypoint Platform username and password.    4. In Exchange, search for \"s3\".    5. Select the connector and click **Add to project**.    6. Follow the prompts to install the connector.  ### Add the Connector in Studio    1. In Studio, create a Mule project.    2. In the Mule Palette view, click **(X) Search in Exchange**.    3. In **Add Modules to Project** , type \"s3\" in the search field.    4. Click this connector's name in **Available modules**.    5. Click **Add**.    6. Click **Finish**.  ## Configure an Input Source  Configure an input source for Amazon S3 Connector, such as a connector\n",
      "----\n",
      "\n",
      "Query:  how to create api groups?\n",
      "id:  site-files/_Users_hminooei_Downloads_site_api-manager_2.x_api-groups-creating-groups.txt\n",
      "score:  0.882718623\n",
      "answer:  For example, if you created an API Group instance in a production environment, you can add API instances to the API Group instance only from production.  You create API Groups using the following steps:  Create an API Group  \\+ The first step to creating an API Group that can be used by consumers is to create an API Group. .Add API instances to the new API Group  \\+ After you create the API Group, you then add API instances to this group for the first time.  ## Task Prerequisites  Before you begin, you must have:    * At least one API instance in your organization or business group  Otherwise, you will not be able to find the required organization or business group in the list.    * API Group Administrator permissions to create API Groups  ## Create API Groups  You create an API Group at the organization level.  To create API Groups:    1.\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_api-manager_2.x_api-groups-creating-groups.txt\n",
      "score:  0.881429\n",
      "answer:  From the left menu in **API Manager** , click **API Groups > Create API Groups**.    2. In the **API Group name** field, specify a name for the API Group that you want to create: for example, `Social Chatter`.    3. In the **API Group version** field, specify the version for the API Group: for example, `v1`.    4. Optionally, in the **API Group instance label** field, specify a label for the API Group, such as `Internal` if you want to use it for internal purposes.    5. Click **Continue**.  The **Creating a new group** page is displayed. You are now ready to add API instances to the API Group.  ## Add API Instances to API Groups  Your API Group is not functional until you add the API instances to the group that you want to bundle. When you add API instances to an API Group, you can add:\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_api-manager_2.x_api-groups-landing-page.txt\n",
      "score:  0.874485314\n",
      "answer:  Menu    1. [ ](../../general/index.html)   2. [API Manager](index.html)   3. [Manage API Groups](api-groups-landing-page.html)  # API Groups  Using API Groups enables you to bundle your APIs and resources to solve specific user needs. Instead of using individual resources and APIs from a list, the users can request access to and use these in a package that solves a specific problem for them.  When you create an API Group, you can customize instances of that group with different SLAs and rate limit conditions based on the problem the instance must solve. You can then publish the API Group to Anypoint Exchange so that users can subscribe to the package.  Because each API Group instance can include several API instances, and each instance can be included in multiple API Group instance solutions, package customization options are limitless.  ## How API Groups Works\n",
      "----\n",
      "\n",
      "Query:  mapObject example in dataweave\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.3_dataweave-cookbook-map-an-object-key.txt\n",
      "score:  0.86853379\n",
      "answer:  Menu    1. [ ](../../general/index.html)   2. [DataWeave](index.html)   3. [Map Objects Key](dataweave-cookbook-map-an-object-key.html)  # Map Objects Key  This DataWeave example uses the `mapObject` function to iterate through an array of objects and appends a new object that matches the value of the specified criteria.  Before you begin, note that DataWeave version 2 (`%dw 2.0`) is for Mule 4 apps. For a Mule 3 app, refer to DataWeave version 1 ([`%dw 1.0`](../1.2/dataweave-examples.html)) examples, within the Mule 3.9 documentation set. For other Mule versions, you can use the Mule Runtime version selector in the table of contents.  The input consists of a JSON object with sheets.\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.3_dw-core-functions-mapobject.txt\n",
      "score:  0.867726326\n",
      "answer:  /mulesoft/docs- dataweave/blob/v2.3/modules/ROOT/pages/dw-core-functions-mapobject.adoc)\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.4_dw-core-functions-mapobject.txt\n",
      "score:  0.867598832\n",
      "answer:  /mulesoft/docs- dataweave/blob/v2.4/modules/ROOT/pages/dw-core-functions-mapobject.adoc)\n",
      "----\n",
      "\n",
      "Query:  DataWeave example that sorts an array by a field\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.4_dataweave-cookbook-pick-top-elements.txt\n",
      "score:  0.841477871\n",
      "answer:  Menu    1. [ ](../../general/index.html)   2. [DataWeave](index.html)   3. [DataWeave Language](index.html)   4. [DataWeave Examples](dataweave-cookbook.html)   5. [Pick Top Elements](dataweave-cookbook-pick-top-elements.html)  # Pick Top Elements  This DataWeave example sorts an array of candidates by the score they got in a test, then picks only the ones with the best score, as many as there are open positions to fill. Before you begin, note that 2.x versions of DataWeave are used by Mule 4 apps. For DataWeave in Mule 3 apps, refer to [DataWeave version 1.2 examples](../1.2/dataweave-examples.html). For other DataWeave versions,\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.2_dataweave-quickstart.txt\n",
      "score:  0.838965237\n",
      "answer:  Now try a more complex example that maps and merges fields from items in separate arrays. The point here is simply to provide a taste of DataWeave's ability to handle more complex mappings and transformations needed for some integrations.    1. Replace the current script in the source code area with this one:              %dw 2.0     var myVar = [       { bookId: 101,         title: \"world history\",         price: \"19.99\"       },       {         bookId: 202,         title: 'the great outdoors',         price: \"15.99\"       }     ]     var myVar2 = [       {         bookId: 101,         author: \"john doe\"       },       {         bookId: 202,         author: \"jane doe\"       }     ]     output application/json     ---\n",
      "----\n",
      "\n",
      "id:  site-files/_Users_hminooei_Downloads_site_dataweave_2.4_dataweave-cookbook-output-a-field-when-present.txt\n",
      "score:  0.834163427\n",
      "answer:  Menu    1. [ ](../../general/index.html)   2. [DataWeave](index.html)   3. [DataWeave Language](index.html)   4. [DataWeave Examples](dataweave-cookbook.html)   5. [Output a Field When Present](dataweave-cookbook-output-a-field-when-present.html)  # Output a Field When Present  This DataWeave example outputs a field if it is present in the input, a JSON array. The first object in the array contains `\"insurance\"`, while the second does not. The XML output mirrors this structure. Before you begin, note that 2.x versions of DataWeave are used by Mule 4 apps. For DataWeave in Mule 3 apps, refer to [DataWeave version 1.2 examples](../1.2/dataweave- examples.html).\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(queries)):\n",
    "    print('Query: ', results[n]['query'])\n",
    "    for m in range(3):\n",
    "        print(\"id: \", results[n]['results'][m]['metadata']['document_id'])\n",
    "        print(\"score: \", results[n]['results'][m]['score'])\n",
    "        print(\"answer: \", results[n]['results'][m]['text'])\n",
    "        print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the datastore all we need to do is pass one or more queries to the `/query` endpoint. We can take a few questions from SQuAD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18891"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = data['question'].tolist()\n",
    "# format into the structure needed by the /query endpoint\n",
    "queries = [{'query': queries[i]} for i in range(len(queries))]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use just the first *three* questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'},\n",
       " {'query': 'When did the Scholastic Magazine of Notre dame begin publishing?'},\n",
       " {'query': 'Where is the headquarters of the Congregation of the Holy Cross?'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(\n",
    "    \"http://0.0.0.0:8000/query\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        'queries': queries[:3]\n",
    "    }\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through the responses and see the results returned for each query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "When did the Scholastic Magazine of Notre dame begin publishing?\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Where is the headquarters of the Congregation of the Holy Cross?\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_result in res.json()['results']:\n",
    "    query = query_result['query']\n",
    "    answers = []\n",
    "    scores = []\n",
    "    for result in query_result['results']:\n",
    "        answers.append(result['text'])\n",
    "        scores.append(round(result['score'], 2))\n",
    "    print(\"-\"*70+\"\\n\"+query+\"\\n\\n\"+\"\\n\".join([f\"{s}: {a}\" for a, s in zip(answers, scores)])+\"\\n\"+\"-\"*70+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top results are all relevant as we would have hoped. With that we've finished. The retrieval app API can be shut down, and to save resources the Pinecone index can be deleted within the [Pinecone console](https://app.pinecone.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1979a773a5778de9a5fa593a629dff0ab3c80c2563810d3e6a8dfb123dc01c7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
